{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfK2rapb0ON2HCV88MXJcl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjohn2001/The-Office-Predictor/blob/main/The_Office_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qODzsi8brGn1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Initial importing of data\n",
        "parentURL = 'https://raw.githubusercontent.com/Benjohn2001/The-Office-Predictor/main/parent_reply.csv'\n",
        "talkingURL = 'https://raw.githubusercontent.com/Benjohn2001/The-Office-Predictor/main/talking_head.csv'\n",
        "parentDS = pd.read_csv(parentURL)\n",
        "talkingDS = pd.read_csv(talkingURL)\n",
        "\n",
        "#Drop the columns that are not needed\n",
        "#Rename reply to quote so both datasets have matching column names\n",
        "#Combine both the datasets and use reset_index with drop true to reset indexes\n",
        "#and discard the old indexes, all data is now combined\n",
        "#We have 27899 quotes when combined\n",
        "talkingDS=talkingDS.drop(columns=['quote_id'])\n",
        "parentDS=parentDS.drop(columns=[\"parent_id\", \"parent\"])\n",
        "parentDS=parentDS.rename(columns={'reply': 'quote'})\n",
        "combinedDS = pd.concat([parentDS, talkingDS]).reset_index(drop=True)\n",
        "\n",
        "#Remove quotes of length less than 5, removing 10575 quotes, now 17324 quotes \n",
        "#Specification has limit of 10000 samples so now random sample to 10000\n",
        "i=0\n",
        "for item in combinedDS['quote'].values:\n",
        "    if(len(item.split())<5):\n",
        "        combinedDS=combinedDS.drop(i,axis=0)\n",
        "    i=i+1\n",
        "sampled = combinedDS.sample(n=10000).reset_index(drop=True)\n",
        "\n",
        "#Split dataset in 60% training, 20% validation, and 20% test\n",
        "trainDS=sampled[:6000]\n",
        "validationDS=sampled[6000:8000]\n",
        "testDS=sampled[8000:]\n"
      ]
    }
  ]
}