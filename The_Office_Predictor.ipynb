{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObGjYEsCaytbJK1ajZK+NO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjohn2001/The-Office-Predictor/blob/main/The_Office_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qODzsi8brGn1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Initial importing of data\n",
        "parentURL = 'https://raw.githubusercontent.com/Benjohn2001/The-Office-Predictor/main/parent_reply.csv'\n",
        "talkingURL = 'https://raw.githubusercontent.com/Benjohn2001/The-Office-Predictor/main/talking_head.csv'\n",
        "parentDS = pd.read_csv(parentURL)\n",
        "talkingDS = pd.read_csv(talkingURL)\n",
        "\n",
        "#Drop the columns that are not needed\n",
        "#Rename reply to quote so both datasets have matching column names\n",
        "#Combine both the datasets and use reset_index with drop true to reset indexes\n",
        "#and discard the old indexes, all data is now combined\n",
        "#We have 27899 quotes when combined\n",
        "talkingDS=talkingDS.drop(columns=['quote_id'])\n",
        "parentDS=parentDS.drop(columns=[\"parent_id\", \"parent\"])\n",
        "parentDS=parentDS.rename(columns={'reply': 'quote'})\n",
        "combinedDS = pd.concat([parentDS, talkingDS]).reset_index(drop=True)\n",
        "\n",
        "#Remove quotes of length less than 5, removing 10575 quotes, now 17324 quotes \n",
        "#Specification has limit of 10000 samples so now random sample to 10000\n",
        "i=0\n",
        "for item in combinedDS['quote'].values:\n",
        "    if(len(item.split())<5):\n",
        "        combinedDS=combinedDS.drop(i,axis=0)\n",
        "    i=i+1\n",
        "sampled = combinedDS.sample(n=10000).reset_index(drop=True)\n",
        "\n",
        "#Split dataset in 60% training, 20% validation, and 20% test\n",
        "trainDS=sampled[:6000]\n",
        "validationDS=sampled[6000:8000]\n",
        "testDS=sampled[8000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampledCounts=sampled['character'].value_counts()\n",
        "trainCounts=trainDS['character'].value_counts()\n",
        "validationCounts=validationDS['character'].value_counts()\n",
        "testCounts=testDS['character'].value_counts()\n",
        "\n",
        "tableDataCount={\n",
        "    'Dataset':['Initial', 'Train', 'Validation', 'Test'],\n",
        "    'Michael':[sampledCounts['Michael'],trainCounts['Michael'],validationCounts['Michael'],testCounts['Michael']],\n",
        "    'Dwight':[sampledCounts['Dwight'],trainCounts['Dwight'],validationCounts['Dwight'],testCounts['Dwight']],\n",
        "    'Jim':[sampledCounts['Jim'],trainCounts['Jim'],validationCounts['Jim'],testCounts['Jim']],\n",
        "    'Pam':[sampledCounts['Pam'],trainCounts['Pam'],validationCounts['Pam'],testCounts['Pam']],\n",
        "}\n",
        "\n",
        "tableDataPercent={\n",
        "    'Dataset':['Initial', 'Train', 'Validation', 'Test'],\n",
        "    'Michael':[str(round(sampledCounts['Michael']/10000*100,2)),str(round(trainCounts['Michael']/6000*100,2)),str(round(validationCounts['Michael']/2000*100,2)),str(round(testCounts['Michael']/2000*100,2))],\n",
        "    'Dwight':[str(round(sampledCounts['Dwight']/10000*100,2)),str(round(trainCounts['Dwight']/6000*100,2)),str(round(validationCounts['Dwight']/2000*100,2)),str(round(testCounts['Dwight']/2000*100,2))],\n",
        "    'Jim':[str(round(sampledCounts['Jim']/10000*100,2)),str(round(trainCounts['Jim']/6000*100,2)),str(round(validationCounts['Jim']/2000*100,2)),str(round(testCounts['Jim']/2000*100,2))],\n",
        "    'Pam':[str(round(sampledCounts['Pam']/10000*100,2)),str(round(trainCounts['Pam']/6000*100,2)),str(round(validationCounts['Pam']/2000*100,2)),str(round(testCounts['Pam']/2000*100,2))],\n",
        "}\n",
        "\n",
        "tableFrameCount=pd.DataFrame(tableDataCount)\n",
        "print('Table displaying the amount of quotes for each character in each dataset\\n')\n",
        "print(tableFrameCount.to_string(index=False))\n",
        "\n",
        "tableFramePercent=pd.DataFrame(tableDataPercent)\n",
        "print('\\nTable displaying the percentage of character quotes in each dataset\\n')\n",
        "print(tableFramePercent.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIB3QgRmCS6_",
        "outputId": "f1a22a94-9ee6-4253-a3a1-58c64fcbfb05"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table displaying the amount of quotes for each character in each dataset\n",
            "\n",
            "   Dataset  Michael  Dwight  Jim  Pam\n",
            "   Initial     4146    2396 1932 1526\n",
            "     Train     2468    1470 1160  902\n",
            "Validation      831     473  379  317\n",
            "      Test      847     453  393  307\n",
            "\n",
            "Table displaying the percentage of character quotes in each dataset\n",
            "\n",
            "   Dataset Michael Dwight   Jim   Pam\n",
            "   Initial   41.46  23.96 19.32 15.26\n",
            "     Train   41.13   24.5 19.33 15.03\n",
            "Validation   41.55  23.65 18.95 15.85\n",
            "      Test   42.35  22.65 19.65 15.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgvltBE9hMS3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}